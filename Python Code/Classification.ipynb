{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"c:/Users/Mohan/Desktop/Data Sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "data1=pd.read_csv('cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first column as it is only an identifier\n",
    "data1=data1.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the target variable ‘diagnosis’ which is the variable to predict\n",
    "#Get a count of diagnosis observations by type\n",
    "data1.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recode the target variable 'diagnosis' to contain the labels 'Malignant' and 'Benign'\n",
    "data1['diagnosis'].replace(['M','B'],['Malignant','Benign'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>Benign</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    Malignant        17.99         10.38          122.80     1001.0   \n",
       "1    Malignant        20.57         17.77          132.90     1326.0   \n",
       "2    Malignant        19.69         21.25          130.00     1203.0   \n",
       "3    Malignant        11.42         20.38           77.58      386.1   \n",
       "4    Malignant        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564  Malignant        21.56         22.39          142.00     1479.0   \n",
       "565  Malignant        20.13         28.25          131.20     1261.0   \n",
       "566  Malignant        16.60         28.08          108.30      858.1   \n",
       "567  Malignant        20.60         29.33          140.10     1265.0   \n",
       "568     Benign         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get summary of parameters\n",
    "x=data1.loc[:, ['radius_mean','area_mean','smoothness_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean    area_mean  smoothness_mean\n",
       "count   569.000000   569.000000       569.000000\n",
       "mean     14.127292   654.889104         0.096360\n",
       "std       3.524049   351.914129         0.014064\n",
       "min       6.981000   143.500000         0.052630\n",
       "25%      11.700000   420.300000         0.086370\n",
       "50%      13.370000   551.100000         0.095870\n",
       "75%      15.780000   782.700000         0.105300\n",
       "max      28.110000  2501.000000         0.163400"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data1.iloc[:,1:31]\n",
    "y=data1.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Malignant\n",
       "1      Malignant\n",
       "2      Malignant\n",
       "3      Malignant\n",
       "4      Malignant\n",
       "         ...    \n",
       "564    Malignant\n",
       "565    Malignant\n",
       "566    Malignant\n",
       "567    Malignant\n",
       "568       Benign\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['diagnosis'].replace(['Malignant','Benign'],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply normalization to rescale the features to a standard range of values.\n",
    "#Normalize the numeric variables from column2 to column 31 in the dataframe\n",
    "minmax=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "minmax.fit(x).transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     569.000000\n",
       "mean      654.889104\n",
       "std       351.914129\n",
       "min       143.500000\n",
       "25%       420.300000\n",
       "50%       551.100000\n",
       "75%       782.700000\n",
       "max      2501.000000\n",
       "Name: area_mean, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['area_mean'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>10.900</td>\n",
       "      <td>12.96</td>\n",
       "      <td>68.69</td>\n",
       "      <td>366.8</td>\n",
       "      <td>0.07515</td>\n",
       "      <td>0.03718</td>\n",
       "      <td>0.00309</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>...</td>\n",
       "      <td>12.36</td>\n",
       "      <td>18.20</td>\n",
       "      <td>78.07</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.08294</td>\n",
       "      <td>0.01854</td>\n",
       "      <td>0.03953</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.07685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506</td>\n",
       "      <td>12.220</td>\n",
       "      <td>20.04</td>\n",
       "      <td>79.47</td>\n",
       "      <td>453.1</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.11520</td>\n",
       "      <td>0.08175</td>\n",
       "      <td>0.021660</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.06894</td>\n",
       "      <td>...</td>\n",
       "      <td>13.16</td>\n",
       "      <td>24.17</td>\n",
       "      <td>85.13</td>\n",
       "      <td>515.3</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.23150</td>\n",
       "      <td>0.35350</td>\n",
       "      <td>0.08088</td>\n",
       "      <td>0.2709</td>\n",
       "      <td>0.08839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>19.730</td>\n",
       "      <td>19.82</td>\n",
       "      <td>130.70</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.18490</td>\n",
       "      <td>0.24170</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.06697</td>\n",
       "      <td>...</td>\n",
       "      <td>25.28</td>\n",
       "      <td>25.59</td>\n",
       "      <td>159.80</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.59550</td>\n",
       "      <td>0.84890</td>\n",
       "      <td>0.25070</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.12970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>12.470</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.10580</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.038210</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06373</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.23780</td>\n",
       "      <td>0.26710</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>12.980</td>\n",
       "      <td>19.35</td>\n",
       "      <td>84.52</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.09579</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.07107</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.06540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.42</td>\n",
       "      <td>21.95</td>\n",
       "      <td>99.21</td>\n",
       "      <td>634.3</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>0.32530</td>\n",
       "      <td>0.34390</td>\n",
       "      <td>0.09858</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.09166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>11.890</td>\n",
       "      <td>18.35</td>\n",
       "      <td>77.32</td>\n",
       "      <td>432.2</td>\n",
       "      <td>0.09363</td>\n",
       "      <td>0.11540</td>\n",
       "      <td>0.06636</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.06314</td>\n",
       "      <td>...</td>\n",
       "      <td>13.25</td>\n",
       "      <td>27.10</td>\n",
       "      <td>86.20</td>\n",
       "      <td>531.2</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>0.30460</td>\n",
       "      <td>0.28060</td>\n",
       "      <td>0.11380</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.08365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>...</td>\n",
       "      <td>7.93</td>\n",
       "      <td>19.54</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.12020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>18.610</td>\n",
       "      <td>20.25</td>\n",
       "      <td>122.10</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>0.09440</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.077310</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.05699</td>\n",
       "      <td>...</td>\n",
       "      <td>21.31</td>\n",
       "      <td>27.26</td>\n",
       "      <td>139.90</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.21170</td>\n",
       "      <td>0.34460</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.07421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>12.910</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>13.88</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.15060</td>\n",
       "      <td>0.17640</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>21.160</td>\n",
       "      <td>23.04</td>\n",
       "      <td>137.20</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>0.09428</td>\n",
       "      <td>0.10220</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05278</td>\n",
       "      <td>...</td>\n",
       "      <td>29.17</td>\n",
       "      <td>35.59</td>\n",
       "      <td>188.00</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.31550</td>\n",
       "      <td>0.20090</td>\n",
       "      <td>0.2822</td>\n",
       "      <td>0.07526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "159       10.900         12.96           68.69      366.8          0.07515   \n",
       "506       12.220         20.04           79.47      453.1          0.10960   \n",
       "252       19.730         19.82          130.70     1206.0          0.10620   \n",
       "204       12.470         18.60           81.09      481.9          0.09965   \n",
       "331       12.980         19.35           84.52      514.0          0.09579   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "216       11.890         18.35           77.32      432.2          0.09363   \n",
       "101        6.981         13.43           43.79      143.5          0.11700   \n",
       "27        18.610         20.25          122.10     1094.0          0.09440   \n",
       "195       12.910         16.33           82.53      516.4          0.07941   \n",
       "23        21.160         23.04          137.20     1404.0          0.09428   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "159           0.03718         0.00309             0.006588         0.1442   \n",
       "506           0.11520         0.08175             0.021660         0.2124   \n",
       "252           0.18490         0.24170             0.097400         0.1733   \n",
       "204           0.10580         0.08005             0.038210         0.1925   \n",
       "331           0.11250         0.07107             0.029500         0.1761   \n",
       "..                ...             ...                  ...            ...   \n",
       "216           0.11540         0.06636             0.031420         0.1967   \n",
       "101           0.07568         0.00000             0.000000         0.1930   \n",
       "27            0.10660         0.14900             0.077310         0.1697   \n",
       "195           0.05366         0.03873             0.023770         0.1829   \n",
       "23            0.10220         0.10970             0.086320         0.1769   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "159                 0.05743  ...         12.36          18.20   \n",
       "506                 0.06894  ...         13.16          24.17   \n",
       "252                 0.06697  ...         25.28          25.59   \n",
       "204                 0.06373  ...         14.97          24.64   \n",
       "331                 0.06540  ...         14.42          21.95   \n",
       "..                      ...  ...           ...            ...   \n",
       "216                 0.06314  ...         13.25          27.10   \n",
       "101                 0.07818  ...          7.93          19.54   \n",
       "27                  0.05699  ...         21.31          27.26   \n",
       "195                 0.05667  ...         13.88          22.00   \n",
       "23                  0.05278  ...         29.17          35.59   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "159            78.07       470.0            0.1171            0.08294   \n",
       "506            85.13       515.3            0.1402            0.23150   \n",
       "252           159.80      1933.0            0.1710            0.59550   \n",
       "204            96.05       677.9            0.1426            0.23780   \n",
       "331            99.21       634.3            0.1288            0.32530   \n",
       "..               ...         ...               ...                ...   \n",
       "216            86.20       531.2            0.1405            0.30460   \n",
       "101            50.41       185.2            0.1584            0.12020   \n",
       "27            139.90      1403.0            0.1338            0.21170   \n",
       "195            90.81       600.6            0.1097            0.15060   \n",
       "23            188.00      2615.0            0.1401            0.26000   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "159          0.01854               0.03953          0.2738   \n",
       "506          0.35350               0.08088          0.2709   \n",
       "252          0.84890               0.25070          0.2749   \n",
       "204          0.26710               0.10150          0.3014   \n",
       "331          0.34390               0.09858          0.3596   \n",
       "..               ...                   ...             ...   \n",
       "216          0.28060               0.11380          0.3397   \n",
       "101          0.00000               0.00000          0.2932   \n",
       "27           0.34460               0.14900          0.2341   \n",
       "195          0.17640               0.08235          0.3024   \n",
       "23           0.31550               0.20090          0.2822   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "159                  0.07685  \n",
       "506                  0.08839  \n",
       "252                  0.12970  \n",
       "204                  0.08750  \n",
       "331                  0.09166  \n",
       "..                       ...  \n",
       "216                  0.08365  \n",
       "101                  0.09382  \n",
       "27                   0.07421  \n",
       "195                  0.06949  \n",
       "23                   0.07526  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159    0\n",
       "506    0\n",
       "252    1\n",
       "204    0\n",
       "331    0\n",
       "      ..\n",
       "216    0\n",
       "101    0\n",
       "27     1\n",
       "195    0\n",
       "23     1\n",
       "Name: diagnosis, Length: 455, dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>10.48</td>\n",
       "      <td>14.98</td>\n",
       "      <td>67.49</td>\n",
       "      <td>333.6</td>\n",
       "      <td>0.09816</td>\n",
       "      <td>0.10130</td>\n",
       "      <td>0.063350</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06915</td>\n",
       "      <td>...</td>\n",
       "      <td>12.13</td>\n",
       "      <td>21.57</td>\n",
       "      <td>81.41</td>\n",
       "      <td>440.4</td>\n",
       "      <td>0.1327</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.09310</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>0.09646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>10.80</td>\n",
       "      <td>9.71</td>\n",
       "      <td>68.77</td>\n",
       "      <td>357.6</td>\n",
       "      <td>0.09594</td>\n",
       "      <td>0.05736</td>\n",
       "      <td>0.025310</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>...</td>\n",
       "      <td>11.60</td>\n",
       "      <td>12.02</td>\n",
       "      <td>73.66</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.04603</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.07699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>23.09</td>\n",
       "      <td>19.83</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>0.09342</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.05484</td>\n",
       "      <td>...</td>\n",
       "      <td>30.79</td>\n",
       "      <td>23.87</td>\n",
       "      <td>211.50</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.2908</td>\n",
       "      <td>0.07277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>25.73</td>\n",
       "      <td>17.46</td>\n",
       "      <td>174.20</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.11490</td>\n",
       "      <td>0.23630</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>33.13</td>\n",
       "      <td>23.58</td>\n",
       "      <td>229.30</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.645100</td>\n",
       "      <td>0.27560</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.08815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>11.67</td>\n",
       "      <td>20.02</td>\n",
       "      <td>75.21</td>\n",
       "      <td>416.2</td>\n",
       "      <td>0.10160</td>\n",
       "      <td>0.09453</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.021570</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.06461</td>\n",
       "      <td>...</td>\n",
       "      <td>13.35</td>\n",
       "      <td>28.81</td>\n",
       "      <td>87.00</td>\n",
       "      <td>550.6</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>0.08120</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>0.08950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>23.51</td>\n",
       "      <td>24.27</td>\n",
       "      <td>155.10</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.05506</td>\n",
       "      <td>...</td>\n",
       "      <td>30.67</td>\n",
       "      <td>30.73</td>\n",
       "      <td>202.40</td>\n",
       "      <td>2906.0</td>\n",
       "      <td>0.1515</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.20890</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.07738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>11.06</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.053970</td>\n",
       "      <td>0.033410</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.06907</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>19.90</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>20.34</td>\n",
       "      <td>21.51</td>\n",
       "      <td>135.90</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.18750</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.06670</td>\n",
       "      <td>...</td>\n",
       "      <td>25.30</td>\n",
       "      <td>31.86</td>\n",
       "      <td>171.10</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.534400</td>\n",
       "      <td>0.26850</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.10240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>12.03</td>\n",
       "      <td>17.93</td>\n",
       "      <td>76.09</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.07683</td>\n",
       "      <td>0.03892</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.06070</td>\n",
       "      <td>...</td>\n",
       "      <td>13.07</td>\n",
       "      <td>22.25</td>\n",
       "      <td>82.74</td>\n",
       "      <td>523.4</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.02796</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.07037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511</td>\n",
       "      <td>14.81</td>\n",
       "      <td>14.70</td>\n",
       "      <td>94.66</td>\n",
       "      <td>680.7</td>\n",
       "      <td>0.08472</td>\n",
       "      <td>0.05016</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.025410</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.05348</td>\n",
       "      <td>...</td>\n",
       "      <td>15.61</td>\n",
       "      <td>17.58</td>\n",
       "      <td>101.70</td>\n",
       "      <td>760.2</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.07955</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.06142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "426        10.48         14.98           67.49      333.6          0.09816   \n",
       "166        10.80          9.71           68.77      357.6          0.09594   \n",
       "503        23.09         19.83          152.10     1682.0          0.09342   \n",
       "352        25.73         17.46          174.20     2010.0          0.11490   \n",
       "531        11.67         20.02           75.21      416.2          0.10160   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "339        23.51         24.27          155.10     1747.0          0.10690   \n",
       "342        11.06         14.96           71.49      373.9          0.10330   \n",
       "323        20.34         21.51          135.90     1264.0          0.11700   \n",
       "327        12.03         17.93           76.09      446.0          0.07683   \n",
       "511        14.81         14.70           94.66      680.7          0.08472   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "426           0.10130        0.063350             0.022180         0.1925   \n",
       "166           0.05736        0.025310             0.016980         0.1381   \n",
       "503           0.12750        0.167600             0.100300         0.1505   \n",
       "352           0.23630        0.336800             0.191300         0.1956   \n",
       "531           0.09453        0.042000             0.021570         0.1859   \n",
       "..                ...             ...                  ...            ...   \n",
       "339           0.12830        0.230800             0.141000         0.1797   \n",
       "342           0.09097        0.053970             0.033410         0.1776   \n",
       "323           0.18750        0.256500             0.150400         0.2569   \n",
       "327           0.03892        0.001546             0.005592         0.1382   \n",
       "511           0.05016        0.034160             0.025410         0.1659   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "426                 0.06915  ...         12.13          21.57   \n",
       "166                 0.06400  ...         11.60          12.02   \n",
       "503                 0.05484  ...         30.79          23.87   \n",
       "352                 0.06121  ...         33.13          23.58   \n",
       "531                 0.06461  ...         13.35          28.81   \n",
       "..                      ...  ...           ...            ...   \n",
       "339                 0.05506  ...         30.67          30.73   \n",
       "342                 0.06907  ...         11.92          19.90   \n",
       "323                 0.06670  ...         25.30          31.86   \n",
       "327                 0.06070  ...         13.07          22.25   \n",
       "511                 0.05348  ...         15.61          17.58   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "426            81.41       440.4            0.1327             0.2996   \n",
       "166            73.66       414.0            0.1436             0.1257   \n",
       "503           211.50      2782.0            0.1199             0.3625   \n",
       "352           229.30      3234.0            0.1530             0.5937   \n",
       "531            87.00       550.6            0.1550             0.2964   \n",
       "..               ...         ...               ...                ...   \n",
       "339           202.40      2906.0            0.1515             0.2678   \n",
       "342            79.76       440.0            0.1418             0.2210   \n",
       "323           171.10      1938.0            0.1592             0.4492   \n",
       "327            82.74       523.4            0.1013             0.0739   \n",
       "511           101.70       760.2            0.1139             0.1011   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "426         0.293900               0.09310          0.3020   \n",
       "166         0.104700               0.04603          0.2090   \n",
       "503         0.379400               0.22640          0.2908   \n",
       "352         0.645100               0.27560          0.3690   \n",
       "531         0.275800               0.08120          0.3206   \n",
       "..               ...                   ...             ...   \n",
       "339         0.481900               0.20890          0.2593   \n",
       "342         0.229900               0.10750          0.3301   \n",
       "323         0.534400               0.26850          0.5558   \n",
       "327         0.007732               0.02796          0.2171   \n",
       "511         0.110100               0.07955          0.2334   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "426                  0.09646  \n",
       "166                  0.07699  \n",
       "503                  0.07277  \n",
       "352                  0.08815  \n",
       "531                  0.08950  \n",
       "..                       ...  \n",
       "339                  0.07738  \n",
       "342                  0.09080  \n",
       "323                  0.10240  \n",
       "327                  0.07037  \n",
       "511                  0.06142  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426    0\n",
       "166    0\n",
       "503    1\n",
       "352    1\n",
       "531    0\n",
       "      ..\n",
       "339    1\n",
       "342    0\n",
       "323    1\n",
       "327    0\n",
       "511    0\n",
       "Name: diagnosis, Length: 114, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.astype('int')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Classifier to the Training set\n",
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the Test Set results\n",
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426    0\n",
       "166    0\n",
       "503    1\n",
       "352    1\n",
       "531    0\n",
       "      ..\n",
       "339    1\n",
       "342    0\n",
       "323    1\n",
       "327    0\n",
       "511    0\n",
       "Name: diagnosis, Length: 114, dtype: int32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  4],\n",
       "       [ 5, 39]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf_cm_test = confusion_matrix(y_test,y_pred)\n",
    "clf_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain accuracy\n",
    "accuracy = clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the probability of each test data point\n",
    "#Get the probability distribution\n",
    "probas = clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the probabilities\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=150)\n",
    "plt.hist(probas, bins=20)\n",
    "plt.title('Classification Probabilities')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('# of Instances')\n",
    "plt.xlim([0.5, 1.0])\n",
    "plt.legend(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "1.For most instances, the classifier is very confident of its determination (note the tall bars at 0 and 1 on the x-axis).\n",
    "2.However, there are a number of instances where the classifier is less certain. In some cases, it’s nearly a coin toss (0.59 on the x-axis).\n",
    "3.The model is equally uncertain about both benign and malignant instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ROC curve for the model\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs =clf.predict_proba(x_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT ROC curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test new data\n",
    "example_measures=np.array([15.44,12.54,150.9,998,0.2345,0.3452,0.2891,0.1234,0.3421,0.06879,2.076,0.8079,7.274,168.7,0.009786,0.03804,0.04372,0.02785,0.02002,0.007621,28.75,16.44,192.7,2025,0.1723,0.7752,0.7121,0.3421,0.4802,0.1278\n",
    "])\n",
    "example_measures = example_measures.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(example_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhilashMandadhi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Perform Logistic Regression\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "cls =LogisticRegression(random_state =0)\n",
    "lr_cls=cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "lr_y_test =lr_cls.predict(x_test)\n",
    "lr_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_y_train = lr_cls.predict(x_train)\n",
    "lr_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  0],\n",
       "       [ 8, 36]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr_cm_test = confusion_matrix(y_test, lr_y_test)\n",
    "lr_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "lr_accu_test= accuracy_score(y_test,lr_y_test)\n",
    "lr_accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95824175824175828"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_accu_train= accuracy_score(y_train,lr_y_train)  #train 98--rs=50  \n",
    "lr_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "0.958300691647\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "lr_precision_test =precision_score(y_test, lr_y_test, average='weighted')  \n",
    "print(lr_precision_test)\n",
    "lr_precision_train =precision_score(y_train, lr_y_train, average='weighted')\n",
    "print(lr_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform Naibe Bayes Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classfier =GaussianNB()\n",
    "nb_classfier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on Test and Train\n",
    "nb_y_test = nb_classfier.predict(x_test)  #for test\n",
    "nb_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_y_train=nb_classfier.predict(x_train)#for train\n",
    "nb_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  0],\n",
       "       [ 3, 49]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nb_cm_test = confusion_matrix(y_test,nb_y_test)\n",
    "nb_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "nb_acc_test=accuracy_score(y_test, nb_y_test)\n",
    "nb_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93406593406593408"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_acc_train=accuracy_score(y_train, nb_y_train)  #train  \n",
    "nb_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974898785425\n",
      "0.934266191595\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "nb_precision_test =precision_score(y_test, nb_y_test, average='weighted')  \n",
    "print(nb_precision_test)\n",
    "nb_precision_train =precision_score(y_train, nb_y_train, average='weighted')\n",
    "print(nb_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Classification\n",
    "from sklearn.svm import SVC\n",
    "sc = SVC(kernel='rbf')\n",
    "sc_classifier = sc.fit(x_train,y_train)  #model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign']\n"
     ]
    }
   ],
   "source": [
    "#Predicting on Test and Train data\n",
    "svc_y_test = sc_classifier.predict(x_test)\n",
    "print(svc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Malignant' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Malignant'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Malignant' 'Benign'\n",
      " 'Benign' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Benign' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant' 'Benign' 'Malignant' 'Malignant' 'Benign' 'Benign' 'Benign'\n",
      " 'Benign' 'Benign' 'Benign' 'Benign' 'Malignant' 'Benign' 'Benign'\n",
      " 'Malignant']\n"
     ]
    }
   ],
   "source": [
    "svc_y_train=sc_classifier.predict(x_train)  #train\n",
    "print(svc_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  0],\n",
       "       [44,  0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on test and train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svc_cm_test = confusion_matrix(y_test,svc_y_test)   \n",
    "svc_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287,   0],\n",
       "       [  0, 168]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cm_train =confusion_matrix(y_train, svc_y_train)\n",
    "svc_cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy classsification score\n",
    "from sklearn.metrics import accuracy_score\n",
    "svc_acc_test=accuracy_score(y_test, svc_y_test)  #for test  \n",
    "svc_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_acc_train= accuracy_score(y_train, svc_y_train)  #for train  \n",
    "svc_acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432825484765\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "sv_precision_test= precision_score(y_test, svc_y_test, average='weighted')  \n",
    "print(sv_precision_test)\n",
    "sv_precision_train=precision_score(y_train, svc_y_train, average='weighted')\n",
    "print(sv_precision_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_clf = DecisionTreeClassifier()\n",
    "dtc_clf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "dtc_y_test =dtc_clf.predict(x_test)\n",
    "dtc_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_y_train = dtc_clf.predict(x_train)\n",
    "dtc_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69,  1],\n",
       "       [ 6, 38]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dtc_cm_test = confusion_matrix(y_test, dtc_y_test)\n",
    "dtc_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "dtc_accu_test= accuracy_score(y_test,dtc_y_test)\n",
    "dtc_accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_accu_train= accuracy_score(y_train,dtc_y_train)    \n",
    "dtc_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566131237184\n",
      "0.534705542136\n"
     ]
    }
   ],
   "source": [
    "#Precision score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "dtc_precision_test =precision_score(y_test, dtc_y_test, average='weighted')  \n",
    "print(dtc_precision_test)\n",
    "dtc_precision_train =precision_score(y_train, dtc_y_train, average='weighted')\n",
    "print(dtc_precision_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.552631578947\n",
      "0.536263736264\n"
     ]
    }
   ],
   "source": [
    "#Recall score on Test and Train\n",
    "from sklearn.metrics import recall_score\n",
    "dtc_recall_test=recall_score(y_test,dtc_y_test, average='weighted' )\n",
    "print(dtc_recall_test)\n",
    "dtc_recall_train=recall_score(y_train,dtc_y_train, average='weighted' )\n",
    "print(dtc_recall_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Random Forest Calssifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmf = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "rf_classi = rmf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting on test and train data\n",
    "rf_y_test = rf_classi.predict(x_test)\n",
    "rf_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Malignant',\n",
       "       'Benign', 'Benign', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Benign', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Benign', 'Malignant', 'Malignant', 'Benign', 'Malignant',\n",
       "       'Malignant', 'Benign', 'Malignant', 'Benign', 'Benign',\n",
       "       'Malignant', 'Benign', 'Benign', 'Malignant', 'Benign',\n",
       "       'Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Benign', 'Benign', 'Benign', 'Benign', 'Benign', 'Benign',\n",
       "       'Malignant'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_y_train = rf_classi.predict(x_train)\n",
    "rf_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  3],\n",
       "       [ 9, 35]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Confusion Matrix on Test and Train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rf_cm_test = confusion_matrix(y_test, rf_y_test)\n",
    "rf_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[285,   2],\n",
       "       [ 13, 155]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cm_train = confusion_matrix(y_train, rf_y_train)\n",
    "rf_cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy Score on Test and Train\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf_accu_test= accuracy_score(y_test,rf_y_test)  #test\n",
    "rf_accu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967032967032967"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_accu_train= accuracy_score(y_train,rf_y_train)  \n",
    "rf_accu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.949023393728\n",
      "0.971489104116\n"
     ]
    }
   ],
   "source": [
    "#Precision Score on Test and Train\n",
    "from sklearn.metrics import precision_score\n",
    "rf_precision_test =precision_score(y_test, rf_y_test, average='weighted')  \n",
    "print(rf_precision_test)  #test data\n",
    "rf_precision_train =precision_score(y_train, rf_y_train, average='weighted')\n",
    "print(rf_precision_train) #train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n",
      "0.971428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "rf_recall_test=recall_score(y_test,rf_y_test, average='weighted' )\n",
    "print(rf_recall_test)\n",
    "rf_recall_train=recall_score(y_train,rf_y_train, average='weighted' )\n",
    "print(rf_recall_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform AdaBoost\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "num_trees = 30\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93478261  0.89130435  0.91304348  0.97826087  0.97826087  0.95555556\n",
      "  0.95555556  0.97777778  0.97777778  1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956231884058\n"
     ]
    }
   ],
   "source": [
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
